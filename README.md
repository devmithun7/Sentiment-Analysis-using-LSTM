# ğŸ“˜ Sentiment Analysis on Amazon Customer Reviews Using Parallel Deep Learning

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9%2B-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/devmithun7/Sentiment-Analysis-using-LSTM)](https://github.com/devmithun7/Sentiment-Analysis-using-LSTM/stargazers)

---

## ğŸ“‹ Table of Contents
- [Project Overview](#project-overview)
- [Project Scope](#project-scope)
- [Dataset](#dataset)
- [Technical Architecture](#technical-architecture)
- [Experiments & Methodology](#experiments--methodology)
- [Parallel Processing Techniques](#parallel-processing-techniques)
- [Results & Analysis](#results--analysis)
- [Repository Structure](#repository-structure)
- [Getting Started](#getting-started)
- [Key Findings](#key-findings)
- [References](#references)

---

## ğŸ¯ Project Overview
This project implements scalable sentiment analysis on **3.5M+ Amazon customer reviews** using parallel data processing and distributed deep learning.  
Techniques such as **Distributed Data Parallelism (DDP)**, **model parallelism**, and **Dask-based preprocessing** were evaluated to measure their impact on **training time, speedup, and efficiency**.

The goal is to understand how parallel computing techniques accelerate large-scale NLP workloads and optimize resource utilization.
(Details sourced from project PDF) 

---

## ğŸ”¬ Project Scope

### **1. Enhance Data Processing Efficiency**
- Parallel ingestion using **Dask**
- Clean and standardize review text (lowercasing, removing non-alphabetic chars)
- Convert multi-class review ratings into binary sentiment labels
- Repartition data for balanced worker workloads
- Generate performance reports (task stream, worker profiles, bandwidth)

### **2. Improve Scalability & Resource Utilization**
- Implement **DistributedDataParallel (DDP)** across multiple CPUs
- Compare scaling behavior for 8, 16, 20, 24, and 28 CPU configurations
- Evaluate communication overhead and bottlenecks

### **3. Optimize Deep Learning Model Training**
- Compare **LSTM** and **GRU**, selecting LSTM for best performance
- Build distributed data loaders with `DistributedSampler`
- Implement model saving and epoch-level evaluation

### **4. Benchmark Performance & Scalability**
- Measure training time reduction with increasing CPUs
- Compute speedup and efficiency metrics
- Evaluate how model parallelism affects performance

---

## ğŸ“Š Dataset

### **Dataset Source**
- Amazon Customer Reviews dataset (Kaggle)
- Two files:  
  - `main_data` (1.5 GB)  
  - `subset_data` (163 MB)

### **Dataset Characteristics**
- Total Records: **3.5M+**
- Labels formatted for fastText:
  - `__label__1` â†’ Negative (1â€“2 stars)  
  - `__label__2` â†’ Positive (4â€“5 stars)
- Neutral (3-star) reviews excluded
- No missing values
- Final Split:
  - **3,600,000** training samples  
  - **400,000** test samples  

### **Preprocessing Pipeline**
- Lowercasing text
- Removing non-alphabetic characters
- Stripping unnecessary whitespace
- Partitioning via Dask for parallel efficiency
- Converting labels into binary sentiment

---

## ğŸ—ï¸ Technical Architecture

### **Model: LSTM-Based Sentiment Classifier**
- Word embeddings
- LSTM encoder
- Fully connected layer with sigmoid output
- Loss: Binary Cross-Entropy
- Optimizer: Adam

### **Distributed Training Setup**
- Backend: **gloo** (CPU)
- Multi-process execution using `torch.multiprocessing.spawn`
- Distributed DataLoader using `DistributedSampler`
- Parallel saving of checkpoints

### **Model Parallel Configuration**
- Embedding + FC on `device0`
- LSTM on `device1`
- Forward pass flow:
  1. Embedding â†’ device0  
  2. LSTM â†’ device1  
  3. FC layer â†’ device0  

---

## ğŸ§ª Experiments & Methodology

### **Training Configurations**
- Epochs: 20
- Batch sizes: distributed across CPU cores
- Hardware: multi-core CPU nodes
- DDP runs: 8, 16, 20, 24, 28 CPUs
- Model Parallel + DDP runs: multiple CPU splits

### **Experimental Goals**
- Identify optimal CPU count for training
- Measure diminishing returns at high CPU counts
- Compare pure DDP vs DDP + Model Parallelism

---

## âš¡ Parallel Processing Techniques

### **1ï¸âƒ£ Distributed Data Parallel (DDP)**

**Concept:**  
Replicate model across processes, each handling unique data shards.

**Implementation Steps:**
- Initialize process group
- Wrap model with `DistributedDataParallel`
- Use `DistributedSampler` for balanced dataset splits
- Synchronize gradients via all-reduce

**Benefits:**
- Near-linear scaling at smaller CPU counts
- No model architecture changes needed

---

### **2ï¸âƒ£ Model Parallelism**

**Concept:**  
Split model layers across multiple CPU devices.

**Device Allocation Example:**
- Device 0: Embedding, FC
- Device 1: LSTM

**Benefits:**
- Better utilization of multiple devices
- Reduces load on single CPU
- Useful for large models

**Trade-offs:**
- Higher communication overhead
- Less efficient if model fits comfortably on one CPU

---

## ğŸ“Š Results & Analysis

### **DDP Performance**
| CPUs | Training Time (min) |
|------|----------------------|
| 8    | 263                  |
| 16   | ~180                 |
| 24   | ~135                 |
| 28   | Higher due to overhead |

**Insights:**
- Training time nearly **cuts in half** from 8 â†’ 24 CPUs
- Best speedup: **1.95Ã—**
- Efficiency decreases with CPU count due to synchronization costs

---

### **DDP + Model Parallel Performance**
- Best performance at **16 CPUs**
- Unstable results at **20 CPUs** due to communication overhead
- Peak speedup: **1.82Ã—**
- Slightly better efficiency at high CPU counts compared to DDP-alone

---

### **Data Preprocessing Performance**
| Tool   | Time (sec) |
|--------|------------|
| Dask   | ~30        |
| Pandas | ~80        |

Dask demonstrates **~3Ã— faster** preprocessing on large files.

---

## ğŸ“ Repository Structure

```plaintext
SentimentAnalysis-DDP/
â”‚
â”œâ”€â”€ data_preprocessing/
â”‚   â””â”€â”€ preprocessing.ipynb
â”‚
â”œâ”€â”€ serial_training/
â”‚   â””â”€â”€ lstm_serial.ipynb
â”‚
â”œâ”€â”€ parallel_training/
â”‚   â”œâ”€â”€ ddp/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ ddp_train.py
â”‚   â”‚   â””â”€â”€ model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ddp_model_parallel/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ ddp_mp_train.py
â”‚   â”‚   â””â”€â”€ model_parallel.py
â”‚
â””â”€â”€ reports/
    â”œâ”€â”€ performance_plots/
    â””â”€â”€ analysis_summary.md
